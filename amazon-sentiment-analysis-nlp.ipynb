{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport bz2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-08T10:08:07.013669Z","iopub.execute_input":"2023-04-08T10:08:07.014684Z","iopub.status.idle":"2023-04-08T10:08:07.040235Z","shell.execute_reply.started":"2023-04-08T10:08:07.014625Z","shell.execute_reply":"2023-04-08T10:08:07.039018Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def get_labels_and_texts(file):\n    labels = []\n    texts = []\n    for line in bz2.BZ2File(file):\n        x = line.decode(\"utf-8\")\n        labels.append(int(x[9]) - 1)\n        texts.append(x[10:].strip())\n    labels = labels[:int(len(labels)*0.01)]\n    texts = texts[:int(len(texts)*0.01)]\n    return np.array(labels), texts\ntrain_labels, train_texts = get_labels_and_texts('../input/amazonreviews/train.ft.txt.bz2')\ntest_labels, test_texts = get_labels_and_texts('../input/amazonreviews/test.ft.txt.bz2')","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:08:07.042396Z","iopub.execute_input":"2023-04-08T10:08:07.043594Z","iopub.status.idle":"2023-04-08T10:09:56.947953Z","shell.execute_reply.started":"2023-04-08T10:08:07.043549Z","shell.execute_reply":"2023-04-08T10:09:56.946916Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df=pd.DataFrame(zip(train_texts,train_labels),columns=['text','label'])\nprint(train_df.head())\ntest_df=pd.DataFrame(zip(test_texts,test_labels),columns=['text','label'])\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:09:56.949398Z","iopub.execute_input":"2023-04-08T10:09:56.949779Z","iopub.status.idle":"2023-04-08T10:09:56.992280Z","shell.execute_reply.started":"2023-04-08T10:09:56.949736Z","shell.execute_reply":"2023-04-08T10:09:56.991209Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"                                                text  label\n0  Stuning even for the non-gamer: This sound tra...      1\n1  The best soundtrack ever to anything.: I'm rea...      1\n2  Amazing!: This soundtrack is my favorite music...      1\n3  Excellent Soundtrack: I truly like this soundt...      1\n4  Remember, Pull Your Jaw Off The Floor After He...      1\n                                                text  label\n0  Great CD: My lovely Pat has one of the GREAT v...      1\n1  One of the best game music soundtracks - for a...      1\n2  Batteries died within a year ...: I bought thi...      0\n3  works fine, but Maha Energy is better: Check o...      1\n4  Great for the non-audiophile: Reviewed quite a...      1\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_df.text[0])","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:09:56.995482Z","iopub.execute_input":"2023-04-08T10:09:56.995890Z","iopub.status.idle":"2023-04-08T10:09:57.003633Z","shell.execute_reply.started":"2023-04-08T10:09:56.995847Z","shell.execute_reply":"2023-04-08T10:09:57.002565Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\n","output_type":"stream"}]},{"cell_type":"code","source":"import regex as re\nimport spacy\nnlp = spacy.load('en_core_web_sm')\nfrom nltk.tokenize import TreebankWordTokenizer\nfrom nltk.stem.regexp import RegexpStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:09:57.005235Z","iopub.execute_input":"2023-04-08T10:09:57.005899Z","iopub.status.idle":"2023-04-08T10:10:21.086704Z","shell.execute_reply.started":"2023-04-08T10:09:57.005860Z","shell.execute_reply":"2023-04-08T10:10:21.085558Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def remove_special_characters(text):\n  text=text.str.lower()\n  text=text.apply(lambda x: re.sub(r'[0-9]+','',x))\n  text=text.apply(lambda x: re.sub(r'@mention',' ',x))\n  text=text.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', ' ',x))\n  text=text.apply(lambda x: re.sub(r\"www.\\[a-z]?\\.?(com)+|[a-z]+\\.(com)\", ' ',x))\n  text=text.apply(lambda x: re.sub(r\"[_\\,\\>\\(\\-:\\)\\\\\\/\\!\\.\\^\\!\\:\\];='#]\",'',x))\n  return text","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:10:21.088357Z","iopub.execute_input":"2023-04-08T10:10:21.089285Z","iopub.status.idle":"2023-04-08T10:10:21.098534Z","shell.execute_reply.started":"2023-04-08T10:10:21.089243Z","shell.execute_reply":"2023-04-08T10:10:21.097505Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df['text']=remove_special_characters(train_df['text'])\ntest_df['text']=remove_special_characters(test_df['text'])","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:10:21.100254Z","iopub.execute_input":"2023-04-08T10:10:21.100656Z","iopub.status.idle":"2023-04-08T10:10:23.831500Z","shell.execute_reply.started":"2023-04-08T10:10:21.100617Z","shell.execute_reply":"2023-04-08T10:10:23.830417Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import text,sequence\n\nMAX_NB_WORDS = 10000\nMAX_SEQUENCE_LENGTH = 250\nEMBEDDING_DIM = 100\ntokenizer = text.Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\ntokenizer.fit_on_texts(train_df['text'].values)\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:10:23.833154Z","iopub.execute_input":"2023-04-08T10:10:23.833569Z","iopub.status.idle":"2023-04-08T10:10:26.025960Z","shell.execute_reply.started":"2023-04-08T10:10:23.833512Z","shell.execute_reply":"2023-04-08T10:10:26.024606Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 86207 unique tokens.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install keras_preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:11:21.977715Z","iopub.execute_input":"2023-04-08T10:11:21.978422Z","iopub.status.idle":"2023-04-08T10:11:32.023783Z","shell.execute_reply.started":"2023-04-08T10:11:21.978382Z","shell.execute_reply":"2023-04-08T10:11:32.022361Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting keras_preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras_preprocessing) (1.16.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras_preprocessing) (1.21.6)\nInstalling collected packages: keras_preprocessing\nSuccessfully installed keras_preprocessing-1.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras_preprocessing.sequence import pad_sequences\n\ntrain_text = tokenizer.texts_to_sequences(train_df['text'].values)\ntrain_text = pad_sequences(train_text, maxlen=MAX_SEQUENCE_LENGTH)\nprint('Shape of data tensor:', train_text.shape)\n\ny = pd.get_dummies(train_df['label']).values\nprint('Shape of label tensor:', y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:11:45.742450Z","iopub.execute_input":"2023-04-08T10:11:45.743103Z","iopub.status.idle":"2023-04-08T10:11:47.910066Z","shell.execute_reply.started":"2023-04-08T10:11:45.743053Z","shell.execute_reply":"2023-04-08T10:11:47.908934Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Shape of data tensor: (36000, 250)\nShape of label tensor: (36000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(train_text,y, test_size = 0.10, random_state = 42)\nprint(X_train.shape,Y_train.shape)\nprint(X_test.shape,Y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:11:47.912234Z","iopub.execute_input":"2023-04-08T10:11:47.913320Z","iopub.status.idle":"2023-04-08T10:11:47.939742Z","shell.execute_reply.started":"2023-04-08T10:11:47.913280Z","shell.execute_reply":"2023-04-08T10:11:47.938555Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(32400, 250) (32400, 2)\n(3600, 250) (3600, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,LSTM,Dropout,SpatialDropout1D,GlobalMaxPooling1D, Dense\nimport tensorflow as tf\n\nmodel = Sequential()\nmodel.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=train_text.shape[1]))\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n# model.add(GlobalMaxPooling1D())\nmodel.add(Dense(units=128, activation='relu'))\nmodel.add(Dense(2, activation='softmax'))\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:12:37.242606Z","iopub.execute_input":"2023-04-08T10:12:37.243178Z","iopub.status.idle":"2023-04-08T10:12:37.445852Z","shell.execute_reply.started":"2023-04-08T10:12:37.243134Z","shell.execute_reply":"2023-04-08T10:12:37.445065Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"sequential_3\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_3 (Embedding)     (None, 250, 100)          1000000   \n                                                                 \n spatial_dropout1d_3 (Spatia  (None, 250, 100)         0         \n lDropout1D)                                                     \n                                                                 \n lstm_3 (LSTM)               (None, 100)               80400     \n                                                                 \n dense_2 (Dense)             (None, 128)               12928     \n                                                                 \n dense_3 (Dense)             (None, 2)                 258       \n                                                                 \n=================================================================\nTotal params: 1,093,586\nTrainable params: 1,093,586\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nepochs = 5\nbatch_size = 64\n\nhistory = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,\n                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])","metadata":{"execution":{"iopub.status.busy":"2023-04-08T10:12:37.447780Z","iopub.execute_input":"2023-04-08T10:12:37.448139Z","iopub.status.idle":"2023-04-08T10:54:12.188990Z","shell.execute_reply.started":"2023-04-08T10:12:37.448101Z","shell.execute_reply":"2023-04-08T10:54:12.187930Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/5\n456/456 [==============================] - 538s 1s/step - loss: 0.4092 - accuracy: 0.8079 - val_loss: 0.2891 - val_accuracy: 0.8830\nEpoch 2/5\n456/456 [==============================] - 500s 1s/step - loss: 0.2374 - accuracy: 0.9089 - val_loss: 0.2867 - val_accuracy: 0.8815\nEpoch 3/5\n456/456 [==============================] - 489s 1s/step - loss: 0.1751 - accuracy: 0.9368 - val_loss: 0.3180 - val_accuracy: 0.8877\nEpoch 4/5\n456/456 [==============================] - 484s 1s/step - loss: 0.1339 - accuracy: 0.9528 - val_loss: 0.3971 - val_accuracy: 0.8895\nEpoch 5/5\n456/456 [==============================] - 484s 1s/step - loss: 0.1058 - accuracy: 0.9629 - val_loss: 0.4189 - val_accuracy: 0.8855\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"I really enjoyed this movie. The acting was great and the plot was engaging. Highly recommend!\"\n# preprocess the text data\n# text = preprocess_text(text)\ntext_sequence = tokenizer.texts_to_sequences([text])\npadded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\nprediction = model.predict(padded_sequence)\npredicted_class = np.argmax(prediction)\nsentiment = \"positive\" if predicted_class == 1 else \"negative\"\nprint(\"The sentiment of the text is:\", sentiment)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:02:02.115846Z","iopub.execute_input":"2023-04-08T11:02:02.116238Z","iopub.status.idle":"2023-04-08T11:02:02.511447Z","shell.execute_reply.started":"2023-04-08T11:02:02.116203Z","shell.execute_reply":"2023-04-08T11:02:02.510317Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 338ms/step\nThe sentiment of the text is: positive\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"The product was a complete waste of money. It broke within a week and the customer service was terrible.\"\n\ntext_sequence = tokenizer.texts_to_sequences([text])\npadded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\nprediction = model.predict(padded_sequence)\npredicted_class = np.argmax(prediction)\nsentiment = \"positive\" if predicted_class == 1 else \"negative\"\nprint(\"The sentiment of the text is:\", sentiment)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:03:04.411250Z","iopub.execute_input":"2023-04-08T11:03:04.411789Z","iopub.status.idle":"2023-04-08T11:03:04.542424Z","shell.execute_reply.started":"2023-04-08T11:03:04.411750Z","shell.execute_reply":"2023-04-08T11:03:04.541301Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 82ms/step\nThe sentiment of the text is: negative\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"I was really disappointed with this hotel. The room was dirty and the staff was unhelpful.\"\n\ntext_sequence = tokenizer.texts_to_sequences([text])\npadded_sequence = pad_sequences(text_sequence, maxlen=MAX_SEQUENCE_LENGTH)\nprediction = model.predict(padded_sequence)\npredicted_class = np.argmax(prediction)\nsentiment = \"positive\" if predicted_class == 1 else \"negative\"\nprint(\"The sentiment of the text is:\", sentiment)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:03:35.378638Z","iopub.execute_input":"2023-04-08T11:03:35.379372Z","iopub.status.idle":"2023-04-08T11:03:35.509713Z","shell.execute_reply.started":"2023-04-08T11:03:35.379333Z","shell.execute_reply":"2023-04-08T11:03:35.508732Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 82ms/step\nThe sentiment of the text is: negative\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save(\"/kaggle/working/model.h5\")\nmodel.save_weights(\"/kaggle/working/model_weights.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:07:02.951133Z","iopub.execute_input":"2023-04-08T11:07:02.952169Z","iopub.status.idle":"2023-04-08T11:07:03.024933Z","shell.execute_reply.started":"2023-04-08T11:07:02.952126Z","shell.execute_reply":"2023-04-08T11:07:03.023847Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n\n# Save the weights as an HDF5 file\nmodel.save_weights(\"weights.h5\")\n\n# Save the weight manifest as JSON\nimport json\nweight_manifest = {}\nfor layer in model.layers:\n    if layer.weights:\n        weight_manifest[layer.name] = [w.name for w in layer.weights]\nwith open(\"weight_manifest.json\", \"w\") as json_file:\n    json.dump(weight_manifest, json_file)","metadata":{"execution":{"iopub.status.busy":"2023-04-08T11:08:32.349183Z","iopub.execute_input":"2023-04-08T11:08:32.349926Z","iopub.status.idle":"2023-04-08T11:08:32.376170Z","shell.execute_reply.started":"2023-04-08T11:08:32.349886Z","shell.execute_reply":"2023-04-08T11:08:32.375219Z"},"trusted":true},"execution_count":27,"outputs":[]}]}